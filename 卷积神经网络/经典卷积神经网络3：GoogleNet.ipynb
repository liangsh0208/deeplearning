{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception模块就是 四个卷积并行的层: 1. 一个1x1的卷积， 一个小的感受野进行卷积提取特征。 2. 一个1x1的卷积加上一个3x3的卷积， 1x1卷积降低输入的特征通道，减少参数数量， 3x3的卷积做一个较大感受野的卷积。 3. 一个1x1的卷积，加一个5x5的卷积。 4. 一个3x3的最大池化加上1x1的卷积，最大池化改变输入的特征排列， 1x1的卷积进行特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "batch_size = 64\n",
    "import cifar10_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/liangsh/新加卷1/天池阿里云/天池课程练习tf/卷积神经网络/cifar10_input.py:158: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /media/liangsh/新加卷1/天池阿里云/天池课程练习tf/卷积神经网络/cifar10_input.py:79: FixedLengthRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.FixedLengthRecordDataset`.\n",
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "WARNING:tensorflow:From /media/liangsh/新加卷1/天池阿里云/天池课程练习tf/卷积神经网络/cifar10_input.py:126: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n",
      "WARNING:tensorflow:From /media/liangsh/新加卷1/天池阿里云/天池课程练习tf/卷积神经网络/cifar10_input.py:132: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    }
   ],
   "source": [
    "images_trains, labels_trains = cifar10_input.distorted_inputs(data_dir=\"../cifar_data/cifar-10-batches-bin/\",\n",
    "                                                              batch_size=batch_size)\n",
    "\n",
    "images_test, labels_test = cifar10_input.inputs(eval_data=True,data_dir=\"../cifar_data/cifar-10-batches-bin/\",\n",
    "                                               batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception(x,d0_1, d1_1, d1_3, d2_1, d2_5, d3_1, scope='inception', reuse=None):\n",
    "    with tf.variable_scope(scope,reuse):\n",
    "        #把slim.conv2d slim.max_pool2d 的默认参数放到slim的参数域中\n",
    "        with slim.arg_scope([slim.conv2d, slim.max_pool2d], stride=1, padding='SAME'):\n",
    "            with tf.variable_scope('branch0'):\n",
    "                branch_0 = slim.conv2d(x, d0_1, [1,1], scope='conv_1x1')\n",
    "            with tf.variable_scope('branch1'):\n",
    "                branch_1 = slim.conv2d(x, d1_1, [1,1], scope='conv_1x1')\n",
    "                branch_1 = slim.conv2d(branch_1, d1_3, [3,3], scope='conv_3x3')\n",
    "            with tf.variable_scope('branch2'):\n",
    "                branch_2 = slim.conv2d(x, d2_1, [1,1], scope='conv_1x1')\n",
    "                branch_2 = slim.conv2d(branch_2, d2_5, [5,5], scope='conv_5x5')\n",
    "            with tf.variable_scope('branch3'):\n",
    "                branch_3 = slim.max_pool2d(x,[3,3], scope='max_pool')\n",
    "                branch_3 = slim.conv2d(branch_3, d3_1, [1,1], scope='conv_1x1')\n",
    "            \n",
    "            net = tf.concat([branch_0, branch_1,branch_2,branch_3], axis=-1)\n",
    "            \n",
    "            return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def googlenet(inputs, num_classes, reuse=None, is_training=None, verbose=False):\n",
    "    with tf.variable_scope('googlenet',reuse=reuse):\n",
    "        with slim.arg_scope([slim.batch_norm], is_training= is_training):\n",
    "            with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d], padding='SAME', stride=1):\n",
    "                net = inputs\n",
    "                with tf.variable_scope('block1'):\n",
    "                    net = slim.conv2d(net, 64, [5,5], stride=2, scope='conv_5x5')\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print('block1 output : {}'.format(net.shape))\n",
    "                with tf.variable_scope('block2'):\n",
    "                    net = slim.conv2d(net, 64, [1,1], scope='conv_1x1')\n",
    "                    net = slim.conv2d(net, 192, [3,3], scope='conv_3x3')\n",
    "                    net = slim.max_pool2d(net, [3,3], stride=2, scope='max_pool')\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print('block2 output: {}'.format(net.shape))\n",
    "                with tf.variable_scope('block3'):\n",
    "                    net = inception(net, 64, 96, 128, 16, 32,32, scope='inception_1')\n",
    "                    net = inception(net, 128, 128, 192,32, 94, 64, scope='inception_2')\n",
    "                    net = slim.max_pool2d(net, [3,3], stride=2, scope='max_pool')\n",
    "                \n",
    "                    if verbose:\n",
    "                        print('block3 output: {}'.format(net.shape))\n",
    "                with tf.variable_scope('block4'):\n",
    "                    net = inception(net, 192, 96, 208, 16, 48, 64, scope = 'inception_1')\n",
    "                    net = inception(net, 160, 112, 224, 24, 64, 64, scope= 'inception_2')\n",
    "                    net = inception(net, 128, 128, 256, 24, 64, 64, scope= 'inception_3')\n",
    "                    net = inception(net, 112, 144, 288, 24, 64, 64, scope= 'inception_4')\n",
    "                    net = inception(net, 256, 160, 320, 32, 128, 128, scope= 'inception_5')\n",
    "                    net = slim.max_pool2d(net, [3,3], stride=2, scope='max_pool')\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print('block4 output: {}'.format(net.shape))\n",
    "                with tf.variable_scope('block5'):\n",
    "                    net = inception(net, 256, 160, 320, 32, 128, 128, scope='inception_1')\n",
    "                    net = inception(net, 384, 182, 384, 48, 128, 128, scope='inception_2')\n",
    "                    net = slim.avg_pool2d(net, [2,2], stride=2, scope='avg_pool')\n",
    "                    if verbose:\n",
    "                        print('block5 output: {}'.format(net.shape))\n",
    "                \n",
    "                with tf.variable_scope('classification'):\n",
    "                    net = slim.flatten(net)\n",
    "                    net = slim.fully_connected(net ,num_classes, activation_fn=None, \n",
    "                                               normalizer_fn=None, scope='light')\n",
    "                    if verbose:\n",
    "                        print('classification output: {}'.format(net.shape))\n",
    "                return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with slim.arg_scope([slim.conv2d], activation_fn = tf.nn.relu, normalizer_fn = slim.batch_norm) as sc:\n",
    "    conv_scope = sc\n",
    "\n",
    "is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "\n",
    "image_holder = tf.placeholder(shape=[batch_size,24,24,3], dtype=tf.float32)\n",
    "label_holder = tf.placeholder(shape=[batch_size], dtype=tf.int32)\n",
    "\n",
    "with slim.arg_scope(conv_scope):\n",
    "    train_out = googlenet(image_holder,10, is_training=is_training, verbose=True)\n",
    "\n",
    "train_out.shape\n",
    "\n",
    "with tf.variable_scope('loss'):\n",
    "    train_loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=train_out,\n",
    "                                                                       labels=label_holder, scope='train'))\n",
    "\n",
    "with tf.variable_scope('accuracy'):\n",
    "    with tf.name_scope('train'):\n",
    "        train_acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(train_out, axis=-1,output_type=tf.int32), \n",
    "                                                    label_holder), tf.float32))\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "opt = tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.9)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_op = opt.minimize(train_loss)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tf.train.start_queue_runners()\n",
    "\n",
    "for i in range(1000):\n",
    "    image_bath, label_batch = sess.run([images_trains, labels_trains])\n",
    "    _, loss1, acc1 = sess.run([train_op,train_loss,train_acc], feed_dict={image_holder: image_bath, label_holder: label_batch, is_training:True})\n",
    "    if i % 10 ==0:\n",
    "        print(\"Step%d  train loss %.6f train acc: %.6f\" % (i+1, loss1, acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
