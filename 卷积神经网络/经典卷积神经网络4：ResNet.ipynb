{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet 是imagenet 2015冠军，\n",
    "#残差网络，基于残差块的堆叠， residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cifar10_input\n",
    "batch_size = 64\n",
    "images_trains, labels_trains = cifar10_input.distorted_inputs(data_dir=\"../cifar_data/cifar-10-batches-bin/\",\n",
    "                                                              batch_size=batch_size)\n",
    "images_test, labels_test = cifar10_input.inputs(eval_data=True,data_dir=\"../cifar_data/cifar-10-batches-bin/\",\n",
    "                                               batch_size=batch_size)\n",
    "\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下采样函数\n",
    "def sub_sample(x, factor, scope=None):\n",
    "    if factor == 1:\n",
    "        return x\n",
    "    return slim.max_pool2d(x,[1,1], scope=scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, bottleneck_depth, out_depth, stride=1, scope='residual_block'):\n",
    "    in_depth = x.get_shape().as_list()[-1]\n",
    "    with tf.variable_scope(scope):\n",
    "        if in_depth == out_depth:\n",
    "            shortcut = sub_sample(x, stride, 'shortcut')\n",
    "        else:\n",
    "            shortcut = slim.conv2d(x,out_depth,[1,1], stride=stride, activation_fn=None,scope='shortcut')\n",
    "        residual = slim.conv2d(x,bottleneck_depth, [1,1], stride=1, scope='conv1')\n",
    "        residual = slim.conv2d(residual, bottleneck_depth, 3, stride, scope='conv2')\n",
    "        residual = slim.conv2d(residual, out_depth, [1,1], stride=1, activation_fn=None, scope='conv3')\n",
    "        \n",
    "        output = tf.nn.relu(shortcut+residual)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(inputs, num_classes, reuse=None, is_training=None, verbose=False):\n",
    "    with tf.variable_scope('resnet',reuse=reuse):\n",
    "        net = inputs\n",
    "        if verbose:\n",
    "            print('input: {}'.format(net.shape))\n",
    "        with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d], padding='SAME'):\n",
    "            with tf.variable_scope('block1'):\n",
    "                net = slim.conv2d(net, 32, [5,5], stride=2, scope='conv_5x5')\n",
    "                if verbose:\n",
    "                    print('block1: {}'.format(net.shape))\n",
    "            with tf.variable_scope('blcok2'):\n",
    "                net = slim.max_pool2d(net, [3,3], 2, scope='max_pool')\n",
    "                net = residual_block(net, 32, 128, scope='residual_block1')\n",
    "                net = residual_block(net, 32, 128, scope='residual_block2')\n",
    "                if verbose:\n",
    "                    print('block2: {}'.format(net.shape))\n",
    "            with tf.variable_scope('block3'):\n",
    "                net = residual_block(net, 64, 256, stride=2, scope='residual_block1')\n",
    "                net = residual_block(net, 64, 256, scope='residual_block2')\n",
    "                if verbose:\n",
    "                    print('block3: {}'.format(net.shape))\n",
    "                \n",
    "            with tf.variable_scope('block4'):\n",
    "                net = residual_block(net, 128, 512, stride=2, scope='residual_block1')\n",
    "                net = residual_block(net, 128, 512, scope='residual_block2')\n",
    "                if verbose:\n",
    "                    print('block4: {}'.format(net.shape))\n",
    "            with tf.variable_scope('classification'):\n",
    "                net = tf.reduce_mean(net, [1,2], name='global_pool', keep_dims=True)\n",
    "                net = slim.flatten(net, scope='flattern')\n",
    "                net = slim.fully_connected(net, num_classes, activation_fn=None, \n",
    "                                           normalizer_fn=None, scope='logit')\n",
    "                if verbose:\n",
    "                    print('classification: {}'.format(net.shape))\n",
    "            return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (64, 24, 24, 3)\n",
      "block1: (64, 12, 12, 32)\n",
      "block2: (64, 6, 6, 128)\n",
      "block3: (64, 3, 3, 256)\n",
      "block4: (64, 2, 2, 512)\n",
      "WARNING:tensorflow:From <ipython-input-12-c68376513b9e>:29: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "classification: (64, 10)\n",
      "WARNING:tensorflow:From <ipython-input-13-06ebe2070ca7>:28: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "Step1  train loss 3.270705 train acc: 0.062500\n",
      "Step11  train loss 2.590307 train acc: 0.078125\n",
      "Step21  train loss 2.765359 train acc: 0.062500\n",
      "Step31  train loss 2.308105 train acc: 0.125000\n",
      "Step41  train loss 2.310807 train acc: 0.140625\n",
      "Step51  train loss 2.176364 train acc: 0.203125\n",
      "Step61  train loss 2.193724 train acc: 0.156250\n",
      "Step71  train loss 2.117293 train acc: 0.234375\n",
      "Step81  train loss 2.089896 train acc: 0.281250\n",
      "Step91  train loss 2.057678 train acc: 0.265625\n",
      "Step101  train loss 2.137844 train acc: 0.234375\n",
      "Step111  train loss 2.160743 train acc: 0.234375\n",
      "Step121  train loss 1.942740 train acc: 0.296875\n",
      "Step131  train loss 2.040877 train acc: 0.312500\n",
      "Step141  train loss 1.953011 train acc: 0.187500\n",
      "Step151  train loss 2.023986 train acc: 0.250000\n",
      "Step161  train loss 2.282068 train acc: 0.187500\n",
      "Step171  train loss 2.022737 train acc: 0.250000\n",
      "Step181  train loss 2.073367 train acc: 0.296875\n",
      "Step191  train loss 1.991529 train acc: 0.281250\n",
      "Step201  train loss 1.945616 train acc: 0.171875\n",
      "Step211  train loss 1.981301 train acc: 0.265625\n",
      "Step221  train loss 2.170481 train acc: 0.250000\n",
      "Step231  train loss 1.781406 train acc: 0.328125\n",
      "Step241  train loss 2.071089 train acc: 0.218750\n",
      "Step251  train loss 2.270663 train acc: 0.203125\n",
      "Step261  train loss 1.977332 train acc: 0.265625\n",
      "Step271  train loss 1.826959 train acc: 0.421875\n",
      "Step281  train loss 1.814515 train acc: 0.296875\n",
      "Step291  train loss 2.035352 train acc: 0.187500\n",
      "Step301  train loss 1.831887 train acc: 0.343750\n",
      "Step311  train loss 1.892613 train acc: 0.312500\n",
      "Step321  train loss 1.923632 train acc: 0.281250\n",
      "Step331  train loss 1.800507 train acc: 0.328125\n",
      "Step341  train loss 1.963567 train acc: 0.343750\n",
      "Step351  train loss 1.965392 train acc: 0.281250\n",
      "Step361  train loss 1.826531 train acc: 0.343750\n",
      "Step371  train loss 1.730302 train acc: 0.390625\n",
      "Step381  train loss 2.065118 train acc: 0.296875\n",
      "Step391  train loss 1.649399 train acc: 0.453125\n",
      "Step401  train loss 1.971530 train acc: 0.265625\n",
      "Step411  train loss 1.785384 train acc: 0.343750\n",
      "Step421  train loss 1.925431 train acc: 0.281250\n",
      "Step431  train loss 1.623369 train acc: 0.437500\n",
      "Step441  train loss 1.878934 train acc: 0.312500\n",
      "Step451  train loss 1.878594 train acc: 0.296875\n",
      "Step461  train loss 2.055932 train acc: 0.218750\n",
      "Step471  train loss 1.948487 train acc: 0.359375\n",
      "Step481  train loss 1.799178 train acc: 0.250000\n",
      "Step491  train loss 1.624955 train acc: 0.421875\n",
      "Step501  train loss 1.755358 train acc: 0.312500\n",
      "Step511  train loss 1.726602 train acc: 0.343750\n",
      "Step521  train loss 1.819291 train acc: 0.343750\n",
      "Step531  train loss 1.609162 train acc: 0.421875\n",
      "Step541  train loss 1.675874 train acc: 0.406250\n",
      "Step551  train loss 1.819572 train acc: 0.359375\n",
      "Step561  train loss 1.668752 train acc: 0.390625\n",
      "Step571  train loss 1.745062 train acc: 0.343750\n",
      "Step581  train loss 1.884800 train acc: 0.375000\n",
      "Step591  train loss 1.660388 train acc: 0.359375\n",
      "Step601  train loss 1.755032 train acc: 0.359375\n",
      "Step611  train loss 1.617912 train acc: 0.359375\n",
      "Step621  train loss 1.813396 train acc: 0.281250\n",
      "Step631  train loss 1.677577 train acc: 0.328125\n",
      "Step641  train loss 1.668961 train acc: 0.468750\n",
      "Step651  train loss 1.863662 train acc: 0.343750\n",
      "Step661  train loss 1.804445 train acc: 0.296875\n",
      "Step671  train loss 2.099294 train acc: 0.250000\n",
      "Step681  train loss 1.627114 train acc: 0.406250\n",
      "Step691  train loss 1.535496 train acc: 0.390625\n",
      "Step701  train loss 1.804362 train acc: 0.390625\n",
      "Step711  train loss 1.843882 train acc: 0.312500\n",
      "Step721  train loss 1.725678 train acc: 0.390625\n",
      "Step731  train loss 1.811392 train acc: 0.390625\n",
      "Step741  train loss 1.908843 train acc: 0.296875\n",
      "Step751  train loss 1.797224 train acc: 0.406250\n",
      "Step761  train loss 1.853304 train acc: 0.375000\n",
      "Step771  train loss 1.609548 train acc: 0.484375\n",
      "Step781  train loss 1.622898 train acc: 0.421875\n",
      "Step791  train loss 1.987459 train acc: 0.359375\n",
      "Step801  train loss 1.706671 train acc: 0.390625\n",
      "Step811  train loss 1.837238 train acc: 0.343750\n",
      "Step821  train loss 1.795876 train acc: 0.421875\n",
      "Step831  train loss 1.765414 train acc: 0.390625\n",
      "Step841  train loss 1.897922 train acc: 0.343750\n",
      "Step851  train loss 1.833972 train acc: 0.296875\n",
      "Step861  train loss 1.563819 train acc: 0.437500\n",
      "Step871  train loss 1.823975 train acc: 0.328125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-06ebe2070ca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mimage_bath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimages_trains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_trains\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mimage_holder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_bath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_holder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step%d  train loss %.6f train acc: %.6f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with slim.arg_scope([slim.conv2d], activation_fn = tf.nn.relu, normalizer_fn = slim.batch_norm) as sc:\n",
    "    conv_scope = sc\n",
    "\n",
    "is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "image_holder = tf.placeholder(shape=[batch_size,24,24,3], dtype=tf.float32)\n",
    "label_holder = tf.placeholder(shape=[batch_size], dtype=tf.int32)\n",
    "\n",
    "with slim.arg_scope(conv_scope):\n",
    "    train_out = resnet(image_holder,10, is_training=is_training, verbose=True)\n",
    "\n",
    "with tf.variable_scope('loss'):\n",
    "    train_loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=train_out,\n",
    "                                                                       labels=label_holder, scope='train'))\n",
    "\n",
    "with tf.variable_scope('accuracy'):\n",
    "    with tf.name_scope('train'):\n",
    "        train_acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(train_out, axis=-1,output_type=tf.int32), \n",
    "                                                    label_holder), tf.float32))\n",
    "\n",
    "lr = 1e-3\n",
    "opt = tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.9)\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_op = opt.minimize(train_loss)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tf.train.start_queue_runners()\n",
    "\n",
    "for i in range(1000):\n",
    "    image_bath, label_batch = sess.run([images_trains, labels_trains])\n",
    "    _, loss1, acc1 = sess.run([train_op,train_loss,train_acc], feed_dict={image_holder: image_bath, label_holder: label_batch, is_training:True})\n",
    "    if i % 10 ==0:\n",
    "        print(\"Step%d  train loss %.6f train acc: %.6f\" % (i+1, loss1, acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
